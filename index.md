# Bioimage analysis tasks to tools guide

The goal of this guide is to provide a quick reference for selecting the right open source tool for a given bioimage analysis task. It's intended to help with getting started with a project, particularly for new comers to (bio)image analysis. The guide is organized by common tasks, such as manual annotation, segmentation, tracking, colocalization, etc., and for each task, a list of commonly used tools is provided. At the end of the guide, there are brief overview descriptions of the tools.  
The guide is not exhaustive: at present the focus is on tools that offer a graphical user interface (GUI) for ease of use, but in the future, we may expand to include command-line tools and libraries. Likewise, suggested tools or plugins are those that are well-supported, have a large user base, and are actively maintained, such that you can easily find help if needed. Where possible we have linked to tutorials or documentation to help you get started.

# Common tasks

## Manually annotating regions of interest

Manual annotation of images can be an important image analysis step, for example for counting objects or obtaining shape descriptors, preparing ground-truth for training machine learning (ML) models, or as a pre-processing step to indicate regions of interest (ROI).

### 2D

For general manual annotations of 2D images that are not very large (e.g. whole slide scans):

- [Fiji](#fiji) provides basic, flexible tools for marking regions of interest and an ROI manager for browsing and saving the regions (a dedicated file format is used). Built-in Measurement tool allows getting shape and intensity measurements for marked regions. Finally, the plugin ecosystem also provides additional annotation tools, for example [AnnotatorJ](https://imagej.net/plugins/annotatorj), which enables instance and semantic object annotations, as well as bounding box annotations.    

- [napari](#napari) provides a Labels layer that permits "painting" over objects/regions in an image to annotate those regions into different classes indicated by different integer values (and colors). These annotations are saved as image files. Additionally, Points and Shapes layers can be used to mark coordinates of interest or indicate areas of interest. For these, the annotations are saved as data tables of coordinates. Additionally, the plugin ecosystem provides a [large number of additional annotations tools](https://www.napari-hub.org/plugins?sort=recentlyUpdated&workflowStep=Image+annotation&page=1). 

#### Large 2D, e.g. whole-slide images

The tools below can be used for general purpose annotations of images of all sizes, both large and small.

- [OMERO.iviewer](#omeroiviewer) can be used for annotating images within the OMERO data management system. It permits performant annotation of ROIs for 2D images and planes. Annotations can include points, arrows, lines, polylines, and polygons. Note that by holding down the Shift key, the polyline and polygon tools allow for drawing freehand annotations. Importantly, the annotations can also have attached comments and provide information regarding the area/length of the ROI. The ROI list is linked to the location of the ROI in the image, enabling easy navigation of annotations. Finally, the ROI table can be exported as a spreadsheet for further analysis. For more information, see the [OMERO.iviewer ROI documentation](https://omero-guides.readthedocs.io/en/latest/iviewer/docs/iviewer_rois.html).

- [QuPath](#qupath) has robust 2D annotation tools for both free-form and polygonal annotations, as well as points. It provides a "wand" tool that is zoom-aware and can enable rapid annotation of ROIs at different zoom levels. QuPath provides shape-based measurements (area, perimeter, length, etc.), but pixel intensity measurements can also be computed on-demand. Importantly, annotations can easily be assigned to classes, enabling them to be used for classification tasks.

### 3D

Annotating 3D images can be challenging and time-consuming, because you typically have to annotate plane-by-plane. However, 3D-centric tools can make things easier. 

- [napari](#napari) Labels layers can be 3D and labels can be edited in 3D mode—though the limitations of a 2D screen and mouse controls can make precise edits challenging. Additionally, while in 2D mode, the `n edit dim` parameter can permit simultaneously painting into adjacent slices based on the brush radius. Finally, there are plugins that can help facillitate 3D annotation, such as  [napari-nD-annotator](https://www.napari-hub.org/plugins/napari-nD-annotator), which permits auto-filling labels and slice interpolation, and [napari-threedee](https://napari-threedee.github.io) that enables using oblique rendering planes for annotation.

- [Paintera](#paintera) enables performant annotation of large 3D datasets, thanks to multiscale rendering. It provides orthogonal views but also, importantly, permits painting on planes that are not aligned with the actual imaging planes. This is particularly useful for labeling complex geometries, such as neurons. It's possible to easily fill contours to quickly annotate areas and annotations of slices can be interpolated into volumes. See [this YouTube video](https://www.youtube.com/watch?v=ZDcK0aCLoRc) for an in-depth tutorial.

## Automated segmentation regions of interest (e.g. cells, tissues)

### Thresholding-based segmentation

Traditional or classical image segmentation utilizes [thresholding](https://bioimagebook.github.io/chapters/2-processing/3-thresholding/thresholding.html) to separate objects from the background based pixel intensity values—a form of semantic segmentation. This process results in a binary mask that can be refined using [morphological operations](https://bioimagebook.github.io/chapters/2-processing/5-morph/morph.html) (dilation, erosion, filling of holes, etc.). Then to segment the individual objects (instance segmentation), [additional transformations](https://bioimagebook.github.io/chapters/2-processing/6-transforms/transforms.html) are performed as part of connected components analysis to label groups of pixels that are connected to each other along with separating touching objects, e.g. watershed algorithm. Note that this is a flexible, generalist approach that can work well for many types of images, but can be limited if signal to noise ratio is poor or objects are not very distinct.

- [Fiji](#fiji) provides all the needed tools for classical segmentation. It offers both [manual and automated thresholding methods](https://imagej.net/ij/docs/guide/146-28.html#sub:Threshold...[T]) (e.g. Otsu thresholding) for obtain binary masks. [A wide range of morphological operations](https://imagej.net/ij/docs/guide/146-29.html#toc-Subsection-29.8) like erosion, dilation, and opening/closing can be used to refine segmented foreground and separate touching objects (e.g. watershed and Voronoi algorithms). Finally, the [Analyze Particles](https://imagej.net/ij/docs/guide/146-30.html#toc-Subsection-30.2) function performs instance segmentation on binary masks using various shape criteria and generates ROIs and [measurements](https://imagej.net/ij/docs/guide/146-30.html#sub:Measure...[m]). Importantly, Fiji also provides a wide range of filtering and processing tools that can be used for pre-processing images before segmentation, as well as a wide range of plugins that can be used for specialized segmentation tasks. For a helpful tutorial on thresholding in Fiji, see [this YouTube video series](https://www.youtube.com/watch?v=3kAY1k5OTx4&list=PLXSm9cHbSZBDh7l7muuDecvWVAoxMfmGD&index=12).

- [CellProfiler](#cellprofiler) permits threshold-based segmentation of cells and cell-like objects. For this one utilizes the `Identify Objects` modules. First, the [`IdentifyPrimaryObjects` module](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/objectprocessing.html#identifyprimaryobjects) is used to segment nuclei-like objects, with extensive parameters available for tuning the thresholding and de-clumping. Next, using the `PrimaryObjects` to guide detection, the [`IdentifySecondaryObjects` module](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/objectprocessing.html#identifysecondaryobjects) will segment cells. Note that CellProfiler has a wide range of [image processing modules](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/imageprocessing.html) that can be used for pre-processing and [Measurement modules](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/measurement.html) that can be used for downstream analysis. For an introduction to segmentation using CellProfiler, please see the [Basic Segmentation tutorial](https://tutorials.cellprofiler.org/#beginner-segmentation).

- [QuPath](#qupath) has two different segmentation tools that use thresholding. First, one can define [threshold-based pixel classifiers](https://qupath.readthedocs.io/en/stable/docs/tutorials/thresholding.html#thresholders-in-qupath), offering a generalist approach to defining ROI (semantic segmentation). However, it also provides a specialized [cell detection tool](https://qupath.readthedocs.io/en/stable/docs/tutorials/cell_detection.html) that uses a combination of thresholding and morphological operations to detect individual cells (instance segmentation). Both of these features in QuPath are well adapted to large 2D images, such as whole slide images, because they can be used at different resolution levels and computed on-the-fly using built in tiling.

## Machine learning segmentation

Machine learning approaches have proven very powerful for segmenting images, especially when objects are not well separated, there is a high amount of noise, poor overall contrast, etc. Rather than just using intensity values, as in thresholding, machine learning models can learn from a large number of features to distinguish between objects and background. This section will be broadly divided into classification-based approaches and deep learning approaches.

### Segmentation using classification-based approaches

Classification-based approaches take computed features and use them to classify each pixel or object as belonging to a particular class (e.g. object or background). This can be done using a wide range of classifiers, such as random forests, support vector machines, etc. Typically they do not require a large amount of training data, so "painting" some labels can be sufficient, but can be limited in their ability to generalize to new data. Importantly, both training and inference can be very fast. Finally, classification approaches can be used for both pixel-wise and object-wise segmentation, meaning that these approaches can be applied to both segment objects, as well as classify those objects into different classes, such a cell or tissue type.

- [ilastik](#ilastik) provides a stand-alone GUI for training and applying pixel and object classification models. For [pixel classification](https://www.ilastik.org/documentation/pixelclassification/pixelclassification), GUI enables the user to sparsely label training data and then select features, such as intensity, texture, and edge features, and then train a classifier. The trained classifier can then be applied to batches of images to segment them. Next, [object classification](https://www.ilastik.org/documentation/objects/objects) can be applied in similar fashion, using the image data and the output of the pixel classifier. 

- [Fiji](#fiji) provides a number of plugins that can be used for classification-based segmentation. A commonly used and versatile plugin is [Trainable Weka Segmentation](https://imagej.net/plugins/tws/), which enables the user to train a classifier using a very wide range of features and then apply it to segment images. Another option is [Labkit](https://imagej.net/plugins/labkit/) which provides an intuitive labeling UI and a performant random forest classifier with optimizations for big data.  Finally, the [ilastik plugin](https://www.ilastik.org/documentation/fiji_export/plugin) can be used to apply pre-trained ilastik models to segment images. 

- [QuPath](#qupath) provides a [Pixel classifier](https://qupath.readthedocs.io/en/stable/docs/tutorials/pixel-classification.html) that can use the built-in annotation tools to train a classifier using a wide range of features, with a live preview. The classifier can be saved and then applied to new images. Additionally, QuPath uses a similar interface for object classification, that can be used for example to [classify cells into different classes based on a wide range of features](https://qupath.readthedocs.io/en/stable/docs/tutorials/cell-classification.html). These features in QuPath are well adapted to large 2D images, such as whole slide images, because they can be used at different resolution levels and computed on-the-fly using built in tiling.

- [napari](#napari) provides a number of plugins that use the napari annotation tools to facilitate training classification-based segmentation algorithms. For example, for training a pixel classifier, [napari-convpaint](https://guiwitz.github.io/napari-convpaint/book/Landing.html) uses sparse annotations and a convolutional neural network (CNN) to extract features for the classification, making the process simple for the user. Alternately, for a more conventional and comprehensive approach, [napari-accelerated-pixel-and-object-classification](https://github.com/haesleinhuepf/napari-accelerated-pixel-and-object-classification#napari-accelerated-pixel-and-object-classification-apoc) can be used to train object and semantic segmentation random forest classifiers, as well as perform object classification.

### Segmentation using deep learning (DL)

Deep learning approaches have made automated segmentation tractable for complex images, such as those with many objects, complex shapes, or low contrast. Deep learning models can learn from a large number of features, but are less interpretable and require a large amount of training data. Further, training can be slow and require a lot of computational resources, particularly graphical processing units (GPU). However, frequently they can generalize well to new data and pre-trained models are available. Typically, deep learning approaches can be used for both pixel-wise and object-wise segmentation, meaning that these approaches can be applied to both segment objects, as well as classify those objects into different classes, such a cell or tissue type. This is a rapidly evolving field with very many algorithms available, most implemented in Python using `torch` or `tensorflow` machine learning frameworks. Here we will focus on robust, most commonly used tools that have a graphical user interface (GUI) for applying and/or training the models.

- [Cellpose](#cellpose) is a state-of-the-art DL algorithm developed for cell segmentation, with a number of pre-trained models that can be used for segmenting cells and nuclei in a wide range of 2D biological images, including both fluorescence imaging and histopathology. These models can be utilized in the Cellpose GUI, which can also be used to fine-tune models to new datasets, or via Python API. Cellpose models can also be used by plugins/extensions for other software (e.g. [qupath-extension-cellpose](https://github.com/BIOP/qupath-extension-cellpose#qupath-cellposeomnipose-extension) or [napari-serialcellpose](https://www.napari-hub.org/plugins/napari-serialcellpose)).  

- [StarDist](https://stardist.net) is a state-of-the-art DL algorithm developed for segmenting nuclei and other star-convex (blob-like) objects in 2D or 3D. Two pre-trained models for segmenting nuclei in 2D are readily available, one for fluorescence images and the other for H&E images. Training of models can be performed using Python API. StarDist does not have a dedicated GUI, however for inference, one can use plugins/extensions: [Fiji StarDist plugin](https://imagej.net/plugins/stardist), [QuPath StarDist extension](https://qupath.readthedocs.io/en/0.4/docs/deep/stardist.html), or [napari StarDist plugin](https://www.napari-hub.org/plugins/stardist-napari).


## Tracking cells and particles

- [Fiji](#fiji) provides access to [TrackMate](https://imagej.net/plugins/trackmate/), a well-established standout in terms of object and particle tracking. It provides a wide range of tracking algorithms, including simple linking, as well as more complex algorithms like the Linear Assignment Problem (LAP) tracking. TrackMate can interface with a wide range of segmentation or spot detection algorithms, so it be used for tracking cells, particles, and other objects in 2D and 3D images of various modalities. It also provides track visualization and analysis tools. For a helpful guide to getting started with TrackMate, see this [Microcourse Youtube video](https://youtu.be/7HWtaikIFcs?t=2).

- [CellProfiler](#cellprofiler) includes a [TrackObjects](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/objectprocessing.html#trackobjects) module that can be used for tracking previously identified Objects over the course of a series of frames. It implements a number of different tracking methods, ranging from a simple overlap approach to LAP tracking. The module can provide a wide range of measurements, such as displacements, object lifetimes, and lineage information. For an example pipeline using TrackObjects, see the [CellProfiler Examples](https://cellprofiler.org/examples/).

- [napari](#napari) provides a [Tracks layer](https://napari.org/stable/howtos/layers/tracks.html) which can be useful for visualization of tracking and has a number of tracking plugins available on the [napari-hub](https://www.napari-hub.org/plugins?search=tracking&sort=relevance&page=1). A few standouts include: [btrack](https://www.napari-hub.org/plugins/btrack) a Bayesian multi-object tracker and [napari-trackastra](https://www.napari-hub.org/plugins/napari-trackastra) a transformer-based cell tracker.

- [ultrack](https://royerlab.github.io/ultrack/index.html) is a large-scale versatile cell tracking package that considers a set of multiple segmentation hypotheses and picks the segments that are most consistent over time, making it less susceptible to mistakes when traditional segmentation fails. It's available as a Python package that is also a [napari plugin](https://royerlab.github.io/ultrack/napari.html) with a GUI widget. Additionally, ultrack provides a [Fiji plugin](https://imagej.github.io/plugins/ultrack) which uses TrackMate for visualization.

## Colocalization

Colocalization aims to quantify the degree of overlap between two or more channels in an image, for example representing subcellular fluorescence markers. This can be done using a number of different metrics, such as Pearson's correlation coefficient or Manders' overlap coefficient. A good overview of these approaches can be found in [this review](https://journals.biologists.com/jcs/article/131/3/jcs211847/77151/Image-co-localization-co-occurrence-versus).

- [Fiji(#fiji) offers a number of [plugins for colocalization analysis](https://imagej.net/imaging/colocalization-analysis), however the currently best supported one is the [JACoP plugin revamped by BIOP](https://forum.image.sc/t/biop-jacop-updated-changed-implementation-of-costes-auto-threshold/95722). It implements both Pearson's and Manders' coefficients, as well as Costes' automated thresholding.

- CellProfiler provides a [MeasureColocalization module](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.6/modules/measurement.html#measurecolocalization) for colocalization analysis. The module can be used to calculate a wide range of metrics, such as Pearson's correlation coefficient, Manders' overlap coefficient, and Rank Weighted Colocalization coefficient. A helpful example/tutorial is provided on the [CellProfiler Examples page](https://cellprofiler.org/examples/).

# Most commonly used generalist tools

## Fiji

[Fiji](https://fiji.sc) is a distribution of the [ImageJ](https://imagej.net/software/imagej/) open-source software package for analyzing scientific images. Fiji (and ImageJ) is Java-based and has an easy-to-install  graphical user interface (GUI) application for Linux, macOS, and Windows. Importantly, Fiji bundles in many popular plugins for image analysis and includes an installer and updater mechanism. A list of all plugins can be found [here](https://imagej.net/list-of-extensions). It has robust support for [macros](https://imagej.net/scripting/macro), including a [recorder](https://imagej.net/scripting/macro#the-recorder), as well as [scripting](https://imagej.net/scripting/). Thanks to the [Bio-formats Importer](https://imagej.net/formats/bio-formats), Fiji can open a wide range of file formats, including many [vendor specific and proprietary ones](https://bio-formats.readthedocs.io/en/stable/supported-formats.html). Overall, Fiji is extremely flexible: it can act as an image viewer, be used for annotation, or serve as a flexible image analysis platform; it has a large user base so getting help can be easier.


## CellProfiler

[CellProfiler](https://cellprofiler.org) is a Python-based software package focused on image processing and analysis. It has an easy-to-install graphical user interface (GUI) application for macOS and Windows that enables setting up `pipelines` that include multiple processing and analysis steps, from reading in the image to exporting a data table. In this way, it was designed to permit batch analysis of images without requiring scripting/coding. It has a wide range of image (pre)processing algorithms implemented as modules, along with extensive in-app documentation. However, it has limited viewing capabilities and no annotation tools. Similarly to Fiji, CellProfiler uses Bio-formats to read a wide range of image file formats. At present, CellProfiler has a modest and experimental [plugin ecosystem](https://github.com/CellProfiler/CellProfiler-plugins).

## QuPath

[QuPath](https://qupath.github.io) is a Java-based image visualization, annotation, and analysis package. It has an easy-to-install graphical user interface (GUI) application for Linux, macOS, and Windows. While many associate QuPath with digital pathology applications, it's actually a general 2D-focused tool that enables manual annotation, as well as automated pixel and object classification. It supports reading images using Bio-formats (as Fiji and CellProfiler), as well as [OpenSlide](https://openslide.org), thus supporting a wide range of image file formats, including those from popular slide scanners. QuPath has excellent performance for large 2D images, like whole slide images, without the need for manual tiling. A Command History and [Groovy scripting](https://qupath.readthedocs.io/en/stable/docs/scripting/index.html) can be used to automate workflows. QuPath has a [modest, but powerful extension ecosystem](https://qupath.readthedocs.io/en/0.4/docs/intro/extensions.html#extensions), but lacks a central listing.

## OMERO.iviewer

[OMERO.iviewer](https://www.openmicroscopy.org/omero/iviewer/) is a web-based viewer for images managed using the [OMERO](https://www.openmicroscopy.org/omero/) data management system. OMERO.iviewer permits performant browsing of large multichannel images remotely (it does not possess 3D rendering capability). Additionally, it has annotation tools for drawing and labeling regions of interest, as well as making simple measurements.

## napari

[napari](https://napari.org/stable/) is a Python image visualization and annotation application. While typically installed as a Python package, it does have [a bundled installation with a Python environment](https://napari.org/dev/tutorials/fundamentals/installation.html#install-as-a-bundled-app) on Linux, macOS, and Windows. napari provides a graphical user interface (GUI) for viewing n-dimensional data, such as images, as well as annotating with points, polygons, or labels. While napari does not include any built-in analysis tools, it seamlessly integrates with [the Scientific Python ecosystem](https://scientific-python.org/specs/core-projects/), as well as Python libraries, thanks to a built-in Python console and Python API. Further, it is [a robust ecosystem of plugins](https://www.napari-hub.org) that enable a wide range of file import, analysis (including machine learning), and annotation functions. 

# Commonly used specialized tools

## Cellpose

[Cellpose](https://www.cellpose.org) is a state-of-the-art generalist cell segmentation deep learning model, implemented in Python using `torch`. It provides a graphical user interface (GUI) segmenting cells and nuclei using different pre-trained models. Pre-trained models can be used with a wide range of cell types and imaging modalities, but the GUI also enables fine-tuning an existing model or training new models. With Cellpose 3.0 additional image restoration features are also available. However, installation requires a Python environment. Note: cellpose has a Python API so it can also be accessed programmatically.

## ilastik

[ilastik](https://www.ilastik.org) is a Python-based machine-learning-based pixel and object classification tool for multidimensional data. It provides a graphical user interface (GUI) application for Linux, macOS, and Windows that provides access to various segmentation and object classification workflows, as well as a tracking workflow. In addition to giving access to pre-trained models, the GUI also enables training classifiers, as well as batch processing. Note: in addition to a stand-alone GUI application, a number of ilastik plugins are available for other software package, for example for [Fiji](#fiji) and [napari](#napari).

## Paintera

[Paintera](https://github.com/saalfeldlab/paintera) is a dedicated annotation tool that was designed for performant annotation of large 3D datasets, thanks to multiscale rendering. It provides orthogonal views but also permits painting planes of structures that are not aligned with the actual imaging planes, such as neurons. It's possible to easily fill contours to quickly annotate areas and, importantly, annotations in multiple slices can be interpolated into 3D volumetric annotations. Finally, it can generate 3D meshes of labels to aid with visualization. 

# Finding more tools

- For a more in-depth curated, categorized listing of open source bioimage analysis tools, see this [`awesome` list](https://github.com/hallvaaw/awesome-biological-image-analysis).
- The [BioImage Informatics Index (Biii)](https://biii.eu), also called "BISE" is a community-curated search engine for finding bioimage analysis software tools, workflows, and training materials. 

# Getting more help

All of the above tools are part of the [image.sc community](https://forum.image.sc), which hosts varied discussions ranging from beginner questions to in-depth bug troubleshooting. In addition to posting questions or leading discussions, the effective `Search`, including `Advanced filters`, enables easy mining this rich resource.  Finally, [the Announcements board](https://forum.image.sc/c/announcements/10) is a great way to keep up with the latest bioimaging tool developments. 